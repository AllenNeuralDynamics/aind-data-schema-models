# import importlib
# from typing import Iterator
import json
# import sys
import os
import csv
from aind_data_access_api.document_db_ssh import (
    DocumentDbSSHClient,
    DocumentDbSSHCredentials,
)
from aind_data_access_api.document_db import Client

API_HOST = "api.allenneuraldynamics-test.org"
# DB_NAME = os.getenv("DB_NAME")
# READWRITE_SECRET = os.getenv("READWRITE_SECRET")
# DOCDB_SSH_TUNNEL_SECRET = os.getenv("DOCDB_SSH_TUNNEL_SECRET")
AWS_DEFAULT_REGION = "us-west-2"
DB_NAME = "reference_data_test"
READWRITE_SECRET = "/aind/dev/docdb/credentials/readwrite"
DOCDB_SSH_TUNNEL_SECRET = "/aind/dev/ssh_tunnel/credentials"
# pydantic_models = {
#     "modalities": "Modality",
#     "organizations": "Organization",
#     "species": "Species",
#     "registry": "Registry"
# }

# enum_models = {
#      "process_names": "ProcessName"
# }

# for mod in {**pydantic_models, **enum_models}.keys():
#     importlib.import_module(f"aind_data_schema_models.{mod}")


# def get_schemas(model_name: str, class_name: str) -> Iterator:
#     """
#     Returns Iterator of classes
#     """
#     module_object = sys.modules[f"aind_data_schema_models.{model_name}"]
#     class_object = getattr(module_object, class_name)
#     # return class_object

#     for schema in class_object._ALL:
#         yield schema


# def get_class_object(model_name: str, class_name: str):
#     """
#     Returns a class object
#     """
#     module_object = sys.modules[f"aind_data_schema_models.{model_name}"]
#     class_object = getattr(module_object, class_name)
#     return class_object



# for models in pydantic_models:
#     schemas_to_write = get_schemas(models, pydantic_models[models])
#     if models == "registry":
#         models = "registries"
#     credentials.collection = models
#     for items in schemas_to_write:
#         contents = items().model_dump_json()
#         json_contents = json.loads(contents)
#         with DocumentDbSSHClient(credentials=credentials) as doc_db_client:
#             filter = {"name": json_contents["name"]}
#             response = doc_db_client.collection.update_one(filter=filter, update={"$set": json_contents}, upsert=True)
#             print(response.raw_result)

# for models in enum_models:
#     class_object = get_class_object(models, enum_models[models])
#     credentials.collection = models
#     dict_to_save = {"enum": [p.value for p in class_object]}
#     json_contents = json.loads(json.dumps(dict_to_save))
#     with DocumentDbSSHClient(credentials=credentials) as doc_db_client:
#         response = doc_db_client.collection.replace_one({}, json_contents)
#         print(response.raw_result)

def csv_to_json(csv_file_path):
    # Initialize an empty list to store the rows
    # data = []
    
    # Open the CSV file
    with open(csv_file_path, mode='r', encoding='utf-8') as csv_file:
        # Use csv.DictReader to convert rows into dictionaries
        csv_reader = csv.DictReader(csv_file)
        
        # Loop through each row and append it to the data list
        for row in csv_reader:
            # data.append(row)
            yield row
    
    # return data

def publish_to_docdb(folder_path, docdb_client):
    # Initialize a dictionary to store all JSON data
    # all_data = {}

    # Loop through the folder to get all files
    for file_name in os.listdir(folder_path):
        if file_name.endswith('.csv'):
            collection = file_name[:-4]
            # docdb_client = Client(host='api.allenneuraldynamics-test.org', database=DB_NAME, collection=collection)
            # credentials.collection = collection
            docdb_client.collection = collection

            print(docdb_client.collection)
            # Get the full path of the CSV file
            csv_file_path = os.path.join(folder_path, file_name)
            
            # Convert CSV to JSON
            json_data = csv_to_json(csv_file_path)
            # print(json_data)
            for records in json_data:
                filter = {"name": records["name"]}
                # print(records)
                response = docdb_client._upsert_one_record(filter, update={"$set": records})
                print(response.json())

            # with DocumentDbSSHClient(credentials=credentials) as doc_db_client:
            #     for records in json_data:
            #         filter = {"name": records["name"]}
            #         response = doc_db_client.collection.update_one(filter=filter, update={"$set": records}, upsert=True)
            #         print(response.raw_result)
    # print(json_data)

    # return all_data

# Example usage:
if __name__ == "__main__":
    folder_path = '../models'
    # credentials = DocumentDbSSHCredentials.from_secrets_manager(
    #   doc_db_secret_name=READWRITE_SECRET,
    #   ssh_secret_name=DOCDB_SSH_TUNNEL_SECRET
    #   )
    # credentials.database = DB_NAME
    docdb_client = Client(host=API_HOST, database=DB_NAME, collection='')
    # with DocumentDbSSHClient(credentials=credentials) as doc_db_client:
    #     response = doc_db_client.collection.replace_one({}, json_data)
    #     print(response.raw_result)

    publish_to_docdb(folder_path, docdb_client)